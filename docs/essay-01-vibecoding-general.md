# Vibecoding: Teaching Artists a Third Way to Work with AI

**Publication:** The Conversation (pitch draft)
**Author:** Douglas Goodwin, Design Media Arts, UCLA
**Length:** ~1,100 words

**Standfirst:** While generative AI promises to make art for us, a growing number of artists want something different—tools that let them make art themselves. A new approach called "vibecoding" offers exactly that.

---

On the first day of my vibecoding course at CalArts, I asked my students what they thought about AI. The room got uncomfortable in a productive way.

"It's not black and white," one student said. "It's like saying glasses are for blind people, or elevators are for lazy people. I'd rather know something about it than just say it's for losers and never touch it."

Another student described using AI to transform old photographs of their mother into images that resembled themself at a younger age—a deeply personal project. "It really depends on intentionality," they said. "You can constantly look at it from different angles."

A third raised the issue most directly: "A lot of problems are caused by the abuse of data. Power needs to be regulated. But how do you define what should be fair?"

No one in the room was a cheerleader for AI. No one was refusing either. They were trying to figure out how to use these tools without losing something essential about why they make art in the first place.

That's what this course is about. Not whether AI is good or bad, but whether there's a way to work with it that preserves what artists actually value: process, intention, understanding, authorship.

---

## The finished-output problem

The most popular AI tools for artists—Midjourney, DALL-E, Runway—share a common design philosophy. You type a prompt, and the system generates a complete work. An image. A video. A finished thing.

This is efficient. It's also hollow.

Artists don't want finished things handed to them. They want to *make* something. The satisfaction of creative work comes from decisions accumulated over time: this color not that one, this curve adjusted, this element removed. When a tool skips the process and delivers a result, it turns artists into curators of AI output rather than authors of their own work.

I've heard artists describe using these tools as a "lottery"—you regenerate and regenerate until something acceptable appears. When it does, you can't fully explain it, reproduce it, or build on it. You selected it. You didn't make it.

Something essential is gone.

---

## Vibecoding as a different approach

"Vibecoding" is a term coined by Andrej Karpathy, the former head of AI at Tesla. The idea is simple: instead of asking AI to generate finished output, you have a conversation with it to write code together. The AI knows syntax, algorithms, common solutions. You know what you want to make and why.

The result is genuinely collaborative. You see every line of code. You can change anything. When something breaks, you debug it together. When something works, you understand why.

In my course, I teach vibecoding through shaders—small programs that generate visual output in real time. Students describe what they want to see: "A swirling pattern of dots, organized by harmonics, with color shifting across the frame." Then they work with an AI assistant to write the code that produces it. When the result isn't right—and it often isn't at first—they iterate. They learn to say things like "the gradient should go left to right, not top to bottom" or "I think we're using the wrong noise algorithm."

This is the opposite of the prompt lottery. Every choice belongs to the student. The AI contributes knowledge; the student contributes intention.

---

## New tools generate new images

In his 1970 book *Expanded Cinema*, Gene Youngblood wrote about the experimental filmmaker Pat O'Neill: "New tools generate new images." O'Neill, a sculptor by training, didn't just point a camera and shoot. He worked through highly technical processes: high-contrast printing, positive/negative layering, optical effects. He named his film *7362* after the Kodak emulsion on which it was shot—emphasizing the purely technical nature of the work.

This is the right parallel for vibecoding. O'Neill worked *through* technical systems that required specialized knowledge. The optical printer was a mediating layer between his vision and the final image. He had to learn its language to realize what he saw in his mind.

The AI assistant is the new optical printer. The artist still provides the vision, but the realization happens through technical processes that require vocabulary and understanding. You learn to speak in code the way O'Neill learned emulsion speeds and optical registration.

The difference from Midjourney or Runway is structural. Those tools skip the technical mediation entirely. You describe a finished image; you receive a finished image. There's no process to master, no technique to understand. With vibecoding, the technical layer remains—you're just learning it in conversation rather than alone.

---

## Friction is the point

One of my students mentioned spending eight hours prompting an AI image generator, feeling more exhausted than satisfied. That's friction without payoff—effort spent spinning a slot machine.

Vibecoding involves friction too, but friction of a different kind. When the code breaks, you have to figure out why. When the AI suggests a solution that doesn't quite work, you have to redirect. You learn to recognize what I call "false summits"—moments when the AI leads you in circles because many people got stuck on the same problem before you.

This difficulty isn't a flaw. It's where judgment forms.

When friction disappears entirely—when you type a sentence and receive a finished painting—thinking doesn't speed up. It evaporates. You've delegated not just the labor but the decisions that make the labor meaningful.

---

## The Luddite stance

On that first day of class, I also talked about the Luddites. Most people use "Luddite" as an insult—someone irrationally opposed to technology. But the actual Luddites were highly skilled weavers who understood exactly how the new machines worked. That's why they knew how to break them.

I think artists today can take a similar stance. Not refusal. Not uncritical adoption. Understanding. Learn how these systems work. See the seams. Then decide, from a position of knowledge, how or whether to use them.

---

## Practice, not answers

My course doesn't resolve the ethics of AI. Neither does vibecoding as a method. The students who worry about data exploitation, job displacement, and the concentration of power in a handful of companies—they're right to worry. Those problems are real and won't be solved by learning to write code.

But vibecoding offers something else: a practice. A way to engage with AI that doesn't require you to either reject it entirely or surrender to it. You stay in conversation. You keep making choices. You maintain the friction that lets judgment form.

"We don't need new answers," a colleague said to me recently. "We need new practices."

That's what I'm trying to teach. Not a position on AI, but a way of working that keeps the questions alive while still making things. Thinking is a practice. This is one way to keep practicing.

---

## Author Bio

Douglas Goodwin teaches experimental writing and creative technology at UCLA's Design Media Arts program. He has used computational methods to generate text and visual work for over two decades.

---

## Notes

- Draft prepared for The Conversation
- General audience essay (~1,100 words)
- Companion piece: "The Grain of the Medium" (shader-specific, more technical)
- Structure: starts with teaching experience, ends with critical stance
- Key themes: finished-output problem, friction as knowledge, practice vs. delegation
