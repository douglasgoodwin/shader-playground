# Week 07 — Midpoint: Audio-Reactive Shaders

**Course:** Vibecoding GLSL Shaders | CalArts Program in Experimental Animation

## Where We Are

Halfway through the course. We connect sound to image — the central act of visual music. Using audio analysis data (spectrum, amplitude, beat detection) as shader inputs, your visuals can listen.

## Topics

- Audio analysis: FFT, frequency bands, amplitude
- Feeding audio data into shaders as uniforms (`u_audioEnergy`, `u_bassEnergy`, `u_audioFreq`)
- Mapping bass/mids/highs to visual parameters
- Smoothing and timing: making reactivity feel musical, not twitchy
- The `/audio/` section's two shaders as starting points
- Review of W04 visual-music studies — what worked, what to push further

## Exercise

Take any shader you've built or modified this semester and make it audio-reactive. Add at least one audio uniform (energy, bass, or frequency data) and map it to a visible parameter (size, color, speed, displacement). Use a music file or the microphone as input. Record a short clip showing the shader responding to sound.
