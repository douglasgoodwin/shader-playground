# Week 09 — Performance, Live Visuals & Porting Shaders

**Course:** Vibecoding GLSL Shaders | CalArts Program in Experimental Animation

## Where We Are

The Bijou show will be a live event. This week we think about shaders as performance — controlling parameters in real time, responding to a room, and making decisions on the fly. We'll also cover how to take your GLSL code beyond the browser and into other creative software, opening up projection mapping, multi-screen setups, and integration with video/audio workflows for the Bijou and beyond.

## Performance Topics

- Real-time control: mouse, keyboard, sliders
- Designing for liveness — which parameters matter, which to expose, which to lock down
- Performing with shaders: rehearsal, timing, improvisation
- The Bijou space: projection, aspect ratio, scale
- Optional: Web MIDI API for hardware controllers

## Porting Topics

GLSL is portable — the fragment shader code you've been writing works in many environments with minor adjustments. Key differences when porting: uniform names and conventions (e.g., `u_time` vs. `iTime` vs. `uTime`), texture sampling, coordinate systems.

### TouchDesigner Tutorial (In-Class)

Importing a GLSL fragment shader into a GLSL TOP, mapping uniforms to TouchDesigner parameters, connecting TD's audio analysis to shader inputs, outputting to projection.

Helpful tutorial: https://www.youtube.com/watch?v=9s7KBSMYC9M

### Other Platforms to Be Aware Of

- **Resolume (ISF):** Uses Interactive Shader Format — essentially GLSL with a JSON header declaring inputs. The closest to a drop-in port. Relevant for VJ work and club visuals.
- **Godot:** Uses a GLSL-like shading language with nearly 1:1 syntax. The easiest game engine port for students who want interactive or installable work without the weight of Unity/Unreal.
- **Unity:** Uses HLSL/ShaderLab, so there's a translation step (different function names, `float4` instead of `vec4`, different coordinate conventions). But the core concepts — uniforms, UVs, distance functions, noise — transfer directly. Unity's Shader Graph (node-based) lets you visually connect the same math you've been writing by hand. Good for interactive installations, VR, and gallery work.
- **Unreal:** Material Editor is node-based but supports Custom HLSL nodes for injecting shader code. Heavier lift than Unity for a simple port, but relevant for students headed toward virtual production and real-time cinematics.

## Exercises

1. **Live Performance:** Prepare a 60-second live performance of any shader. Define your control scheme (what keys/sliders do what), rehearse it, and perform it for the class. The emphasis is on intentional parameter choices, not complexity.
2. **Shader Port:** Take one of your shaders and get it running in a platform other than the browser. TouchDesigner (GLSL TOP) will be demonstrated in class; you may also choose Resolume/ISF, Godot, Unity, or Unreal. Connect at least one parameter (time, mouse, or audio) to the host application's input system. Document what you changed and why.
